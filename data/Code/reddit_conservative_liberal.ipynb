{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L3GqqB-SZlHU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3AcEUN0FZlHa",
        "outputId": "c836fb6d-7b02-4c7c-c88d-caede0c8406b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Political Lean</th>\n",
              "      <th>Score</th>\n",
              "      <th>Id</th>\n",
              "      <th>Subreddit</th>\n",
              "      <th>URL</th>\n",
              "      <th>Num of Comments</th>\n",
              "      <th>Text</th>\n",
              "      <th>Date Created</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No matter who someone is, how they look like, ...</td>\n",
              "      <td>Liberal</td>\n",
              "      <td>1</td>\n",
              "      <td>t5fybt</td>\n",
              "      <td>socialism</td>\n",
              "      <td>https://v.redd.it/ng5fyl7hp2l81</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.646272e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Biden speech draws 38.2 million U.S. TV viewers</td>\n",
              "      <td>Liberal</td>\n",
              "      <td>6</td>\n",
              "      <td>t5fqdn</td>\n",
              "      <td>democrats</td>\n",
              "      <td>https://www.reuters.com/world/us/biden-speech-...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.646271e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>State of the union</td>\n",
              "      <td>Liberal</td>\n",
              "      <td>1</td>\n",
              "      <td>t5fj9a</td>\n",
              "      <td>DemocraticSocialism</td>\n",
              "      <td>https://www.reddit.com/r/DemocraticSocialism/c...</td>\n",
              "      <td>1</td>\n",
              "      <td>Who watched the state of the union last night ...</td>\n",
              "      <td>1.646270e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>We Should Just Give Poor People Money</td>\n",
              "      <td>Liberal</td>\n",
              "      <td>7</td>\n",
              "      <td>t5f7n9</td>\n",
              "      <td>SocialDemocracy</td>\n",
              "      <td>https://youtu.be/a80kRjpubG0</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.646270e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Do it for the Dew</td>\n",
              "      <td>Liberal</td>\n",
              "      <td>6</td>\n",
              "      <td>t5es2c</td>\n",
              "      <td>democrats</td>\n",
              "      <td>https://i.redd.it/drmunn90f2l81.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.646268e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Title Political Lean  Score  \\\n",
              "0  No matter who someone is, how they look like, ...        Liberal      1   \n",
              "1    Biden speech draws 38.2 million U.S. TV viewers        Liberal      6   \n",
              "2                                 State of the union        Liberal      1   \n",
              "3              We Should Just Give Poor People Money        Liberal      7   \n",
              "4                                  Do it for the Dew        Liberal      6   \n",
              "\n",
              "       Id            Subreddit  \\\n",
              "0  t5fybt            socialism   \n",
              "1  t5fqdn            democrats   \n",
              "2  t5fj9a  DemocraticSocialism   \n",
              "3  t5f7n9      SocialDemocracy   \n",
              "4  t5es2c            democrats   \n",
              "\n",
              "                                                 URL  Num of Comments  \\\n",
              "0                    https://v.redd.it/ng5fyl7hp2l81                0   \n",
              "1  https://www.reuters.com/world/us/biden-speech-...                1   \n",
              "2  https://www.reddit.com/r/DemocraticSocialism/c...                1   \n",
              "3                       https://youtu.be/a80kRjpubG0                3   \n",
              "4                https://i.redd.it/drmunn90f2l81.jpg                1   \n",
              "\n",
              "                                                Text  Date Created  \n",
              "0                                                NaN  1.646272e+09  \n",
              "1                                                NaN  1.646271e+09  \n",
              "2  Who watched the state of the union last night ...  1.646270e+09  \n",
              "3                                                NaN  1.646270e+09  \n",
              "4                                                NaN  1.646268e+09  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reddit_politics = pd.read_csv(\"../raw/reddit_dataset.csv\")\n",
        "reddit_politics.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xnTYCuTKeBmX"
      },
      "outputs": [],
      "source": [
        "reddit_politics_shuffled = reddit_politics.sample(frac=1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "A3teR4GPeE-k",
        "outputId": "a0f9c444-0246-4574-d4ae-e3f3a7688147"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Political Lean</th>\n",
              "      <th>Score</th>\n",
              "      <th>Id</th>\n",
              "      <th>Subreddit</th>\n",
              "      <th>URL</th>\n",
              "      <th>Num of Comments</th>\n",
              "      <th>Text</th>\n",
              "      <th>Date Created</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7444</th>\n",
              "      <td>Happy holidays! Socially distanced celebration...</td>\n",
              "      <td>Liberal</td>\n",
              "      <td>24</td>\n",
              "      <td>kh4lsm</td>\n",
              "      <td>feminisms</td>\n",
              "      <td>https://www.nbcnews.com/think/opinion/happy-ho...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.608506e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10822</th>\n",
              "      <td>Sandy Hook families settle with Remington mark...</td>\n",
              "      <td>Conservative</td>\n",
              "      <td>90</td>\n",
              "      <td>st7kvu</td>\n",
              "      <td>Libertarian</td>\n",
              "      <td>https://abcnews.go.com/US/sandy-hook-families-...</td>\n",
              "      <td>152</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.644944e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12647</th>\n",
              "      <td>What is land claimed versus land owned? : newc...</td>\n",
              "      <td>Conservative</td>\n",
              "      <td>1</td>\n",
              "      <td>3sy3aj</td>\n",
              "      <td>anarchocapitalism</td>\n",
              "      <td>https://www.reddit.com/r/newcountryproject/com...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.447626e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>What would you say are some skippable/ less im...</td>\n",
              "      <td>Liberal</td>\n",
              "      <td>2</td>\n",
              "      <td>t1po2s</td>\n",
              "      <td>socialism</td>\n",
              "      <td>https://www.reddit.com/r/socialism/comments/t1...</td>\n",
              "      <td>14</td>\n",
              "      <td>Some of the essays and books that were really ...</td>\n",
              "      <td>1.645855e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3353</th>\n",
              "      <td>2 lawyers arguing against Biden's vaccine mand...</td>\n",
              "      <td>Liberal</td>\n",
              "      <td>730</td>\n",
              "      <td>rybi91</td>\n",
              "      <td>democrats</td>\n",
              "      <td>https://www.businessinsider.com/lawyers-suprem...</td>\n",
              "      <td>64</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.641573e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Title Political Lean  \\\n",
              "7444   Happy holidays! Socially distanced celebration...        Liberal   \n",
              "10822  Sandy Hook families settle with Remington mark...   Conservative   \n",
              "12647  What is land claimed versus land owned? : newc...   Conservative   \n",
              "311    What would you say are some skippable/ less im...        Liberal   \n",
              "3353   2 lawyers arguing against Biden's vaccine mand...        Liberal   \n",
              "\n",
              "       Score      Id          Subreddit  \\\n",
              "7444      24  kh4lsm          feminisms   \n",
              "10822     90  st7kvu        Libertarian   \n",
              "12647      1  3sy3aj  anarchocapitalism   \n",
              "311        2  t1po2s          socialism   \n",
              "3353     730  rybi91          democrats   \n",
              "\n",
              "                                                     URL  Num of Comments  \\\n",
              "7444   https://www.nbcnews.com/think/opinion/happy-ho...                0   \n",
              "10822  https://abcnews.go.com/US/sandy-hook-families-...              152   \n",
              "12647  https://www.reddit.com/r/newcountryproject/com...                0   \n",
              "311    https://www.reddit.com/r/socialism/comments/t1...               14   \n",
              "3353   https://www.businessinsider.com/lawyers-suprem...               64   \n",
              "\n",
              "                                                    Text  Date Created  \n",
              "7444                                                 NaN  1.608506e+09  \n",
              "10822                                                NaN  1.644944e+09  \n",
              "12647                                                NaN  1.447626e+09  \n",
              "311    Some of the essays and books that were really ...  1.645855e+09  \n",
              "3353                                                 NaN  1.641573e+09  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reddit_politics_shuffled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "O7LeZ1DieHT9"
      },
      "outputs": [],
      "source": [
        "reddit_politics_shuffled = reddit_politics_shuffled.drop(\"Id\",axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "reddit_politics_shuffled = reddit_politics_shuffled.drop(\"Score\",axis = 1)\n",
        "reddit_politics_shuffled = reddit_politics_shuffled.drop(\"URL\",axis = 1)\n",
        "reddit_politics_shuffled = reddit_politics_shuffled.drop(\"Num of Comments\",axis = 1)\n",
        "reddit_politics_shuffled = reddit_politics_shuffled.drop(\"Date Created\",axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Political Lean</th>\n",
              "      <th>Subreddit</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7444</th>\n",
              "      <td>Happy holidays! Socially distanced celebration...</td>\n",
              "      <td>Liberal</td>\n",
              "      <td>feminisms</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10822</th>\n",
              "      <td>Sandy Hook families settle with Remington mark...</td>\n",
              "      <td>Conservative</td>\n",
              "      <td>Libertarian</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12647</th>\n",
              "      <td>What is land claimed versus land owned? : newc...</td>\n",
              "      <td>Conservative</td>\n",
              "      <td>anarchocapitalism</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>What would you say are some skippable/ less im...</td>\n",
              "      <td>Liberal</td>\n",
              "      <td>socialism</td>\n",
              "      <td>Some of the essays and books that were really ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3353</th>\n",
              "      <td>2 lawyers arguing against Biden's vaccine mand...</td>\n",
              "      <td>Liberal</td>\n",
              "      <td>democrats</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11964</th>\n",
              "      <td>Avoidable deaths.</td>\n",
              "      <td>Conservative</td>\n",
              "      <td>Capitalism</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5191</th>\n",
              "      <td>Would increasing the minimum wage hurt busines...</td>\n",
              "      <td>Liberal</td>\n",
              "      <td>SocialDemocracy</td>\n",
              "      <td>I am supportive of increasing the minimum wage...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5390</th>\n",
              "      <td>McDonald's Workers Go On Strike, Cite Inadequa...</td>\n",
              "      <td>Liberal</td>\n",
              "      <td>feminisms</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>“Communism is the riddle of history solved, an...</td>\n",
              "      <td>Liberal</td>\n",
              "      <td>socialism</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7270</th>\n",
              "      <td>At least 57 state and local Republican officia...</td>\n",
              "      <td>Liberal</td>\n",
              "      <td>progressive</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12854 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Title Political Lean  \\\n",
              "7444   Happy holidays! Socially distanced celebration...        Liberal   \n",
              "10822  Sandy Hook families settle with Remington mark...   Conservative   \n",
              "12647  What is land claimed versus land owned? : newc...   Conservative   \n",
              "311    What would you say are some skippable/ less im...        Liberal   \n",
              "3353   2 lawyers arguing against Biden's vaccine mand...        Liberal   \n",
              "...                                                  ...            ...   \n",
              "11964                                  Avoidable deaths.   Conservative   \n",
              "5191   Would increasing the minimum wage hurt busines...        Liberal   \n",
              "5390   McDonald's Workers Go On Strike, Cite Inadequa...        Liberal   \n",
              "860    “Communism is the riddle of history solved, an...        Liberal   \n",
              "7270   At least 57 state and local Republican officia...        Liberal   \n",
              "\n",
              "               Subreddit                                               Text  \n",
              "7444           feminisms                                                NaN  \n",
              "10822        Libertarian                                                NaN  \n",
              "12647  anarchocapitalism                                                NaN  \n",
              "311            socialism  Some of the essays and books that were really ...  \n",
              "3353           democrats                                                NaN  \n",
              "...                  ...                                                ...  \n",
              "11964         Capitalism                                                NaN  \n",
              "5191     SocialDemocracy  I am supportive of increasing the minimum wage...  \n",
              "5390           feminisms                                                NaN  \n",
              "860            socialism                                                NaN  \n",
              "7270         progressive                                                NaN  \n",
              "\n",
              "[12854 rows x 4 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reddit_politics_shuffled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Some of the essays and books that were really important must have lost their relevancy for non-academics. For instance, I feel like most people, even not working class, know about the conditions of the poor from documentaries, independent journalism or just interacting with poverty on a daily basis, so Engels' *Conditions of the Working Class in England* is not a very necessary read\""
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reddit_politics_shuffled[\"Text\"].to_list()[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "reddit_politics_shuffled[\"TextComplete\"] = reddit_politics_shuffled[\"Title\"] + \" \" +reddit_politics_shuffled[\"Text\"].fillna(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dgO6jTBchSOy"
      },
      "outputs": [],
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Oración de prueba\n",
        "sentence = \"This is a cat.\"\n",
        "\n",
        "# Traducir la oración\n",
        "inputs = tokenizer([sentence], return_tensors=\"pt\", padding=True)\n",
        "translated = model.generate(**inputs)\n",
        "translated_sentence = tokenizer.decode(translated[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esto es un gato.\n"
          ]
        }
      ],
      "source": [
        "print(translated_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def translate_batch(batch):\n",
        "    inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    translated = model.generate(**inputs)\n",
        "    return [tokenizer.decode(t, skip_special_tokens=True) for t in translated]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Gonzalo\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Cargar el modelo y el tokenizador para inglés a español\n",
        "model_name = 'Helsinki-NLP/opus-mt-en-es'\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def translate_batch(batch):\n",
        "    inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    translated = model.generate(**inputs)\n",
        "    return [tokenizer.decode(t, skip_special_tokens=True) for t in translated]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_translation(batch_number, translated_batch):\n",
        "    output_file = \"traduccion_reddit/translated_batch_{batch_number}.csv\"\n",
        "    df_translated = pd.DataFrame(translated_batch, columns=['translated_statement'])\n",
        "    df_translated.to_csv(output_file, index=False)\n",
        "    print(f\"Batch {batch_number} guardado en {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Traducir la columna 'statement' por lotes para no sobrecargar la memoria\n",
        "# Preparar batches\n",
        "batch_size = 1000\n",
        "batches = [(i//batch_size, reddit_politics_shuffled['TextComplete'][i:i+batch_size].tolist()) for i in range(0, len(reddit_politics_shuffled), batch_size)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[45], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_data \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[0;32m      8\u001b[0m     batch_number, batch \u001b[38;5;241m=\u001b[39m batch_data\n\u001b[1;32m----> 9\u001b[0m     translated_batch \u001b[38;5;241m=\u001b[39m translate_batch(batch)\n\u001b[0;32m     10\u001b[0m     save_translation(batch_number, translated_batch)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[37], line 3\u001b[0m, in \u001b[0;36mtranslate_batch\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranslate_batch\u001b[39m(batch):\n\u001b[0;32m      2\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(batch, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m     translated \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [tokenizer\u001b[38;5;241m.\u001b[39mdecode(t, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m translated]\n",
            "File \u001b[1;32mc:\\Users\\Gonzalo\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Gonzalo\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:1745\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_attention_mask_for_generation(\n\u001b[0;32m   1740\u001b[0m         inputs_tensor, generation_config\u001b[38;5;241m.\u001b[39m_pad_token_tensor, generation_config\u001b[38;5;241m.\u001b[39m_eos_token_tensor\n\u001b[0;32m   1741\u001b[0m     )\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[0;32m   1744\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0;32m   1746\u001b[0m         inputs_tensor, model_kwargs, model_input_name, generation_config\n\u001b[0;32m   1747\u001b[0m     )\n\u001b[0;32m   1749\u001b[0m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
            "File \u001b[1;32mc:\\Users\\Gonzalo\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:549\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[1;34m(self, inputs_tensor, model_kwargs, model_input_name, generation_config)\u001b[0m\n\u001b[0;32m    547\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    548\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[1;32m--> 549\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m encoder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoder_kwargs)\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
            "File \u001b[1;32mc:\\Users\\Gonzalo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Gonzalo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Gonzalo\\anaconda3\\Lib\\site-packages\\transformers\\models\\marian\\modeling_marian.py:736\u001b[0m, in \u001b[0;36mMarianEncoder.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;66;03m# expand attention_mask\u001b[39;00m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m _prepare_4d_attention_mask(attention_mask, inputs_embeds\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    738\u001b[0m encoder_states \u001b[38;5;241m=\u001b[39m () \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    739\u001b[0m all_attentions \u001b[38;5;241m=\u001b[39m () \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Gonzalo\\anaconda3\\Lib\\site-packages\\transformers\\modeling_attn_mask_utils.py:423\u001b[0m, in \u001b[0;36m_prepare_4d_attention_mask\u001b[1;34m(mask, dtype, tgt_len)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_4d_attention_mask\u001b[39m(mask: torch\u001b[38;5;241m.\u001b[39mTensor, dtype: torch\u001b[38;5;241m.\u001b[39mdtype, tgt_len: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    411\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;124;03m    Creates a non-causal 4D mask of shape `(batch_size, 1, query_length, key_value_length)` from a 2D mask of shape\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;124;03m    `(batch_size, key_value_length)`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;124;03m            The target length or query length the created mask shall have.\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AttentionMaskConverter\u001b[38;5;241m.\u001b[39m_expand_mask(mask\u001b[38;5;241m=\u001b[39mmask, dtype\u001b[38;5;241m=\u001b[39mdtype, tgt_len\u001b[38;5;241m=\u001b[39mtgt_len)\n",
            "File \u001b[1;32mc:\\Users\\Gonzalo\\anaconda3\\Lib\\site-packages\\transformers\\modeling_attn_mask_utils.py:184\u001b[0m, in \u001b[0;36mAttentionMaskConverter._expand_mask\u001b[1;34m(mask, dtype, tgt_len)\u001b[0m\n\u001b[0;32m    180\u001b[0m tgt_len \u001b[38;5;241m=\u001b[39m tgt_len \u001b[38;5;28;01mif\u001b[39;00m tgt_len \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m src_len\n\u001b[0;32m    182\u001b[0m expanded_mask \u001b[38;5;241m=\u001b[39m mask[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :]\u001b[38;5;241m.\u001b[39mexpand(bsz, \u001b[38;5;241m1\u001b[39m, tgt_len, src_len)\u001b[38;5;241m.\u001b[39mto(dtype)\n\u001b[1;32m--> 184\u001b[0m inverted_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m expanded_mask\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inverted_mask\u001b[38;5;241m.\u001b[39mmasked_fill(inverted_mask\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mbool), torch\u001b[38;5;241m.\u001b[39mfinfo(dtype)\u001b[38;5;241m.\u001b[39mmin)\n",
            "File \u001b[1;32mc:\\Users\\Gonzalo\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:41\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\Gonzalo\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:962\u001b[0m, in \u001b[0;36mTensor.__rsub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;129m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__rsub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 962\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _C\u001b[38;5;241m.\u001b[39m_VariableFunctions\u001b[38;5;241m.\u001b[39mrsub(\u001b[38;5;28mself\u001b[39m, other)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def process_batch(batch_data):\n",
        "    batch_number, batch = batch_data\n",
        "    translated_batch = translate_batch(batch)\n",
        "    save_translation(batch_number, translated_batch)\n",
        "\n",
        "\n",
        "for batch_data in batches:\n",
        "    batch_number, batch = batch_data\n",
        "    translated_batch = translate_batch(batch)\n",
        "    save_translation(batch_number, translated_batch)\n",
        "    break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
