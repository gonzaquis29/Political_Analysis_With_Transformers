nohup: ignoring input
[nltk_data] Downloading package punkt to /home/gquispe/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt_tab to
[nltk_data]     /home/gquispe/nltk_data...
[nltk_data]   Package punkt_tab is already up-to-date!
[nltk_data] Downloading package stopwords to
[nltk_data]     /home/gquispe/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /home/gquispe/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     /home/gquispe/nltk_data...
[nltk_data]   Package averaged_perceptron_tagger is already up-to-
[nltk_data]       date!
[nltk_data] Downloading package maxent_ne_chunker to
[nltk_data]     /home/gquispe/nltk_data...
[nltk_data]   Package maxent_ne_chunker is already up-to-date!
[nltk_data] Downloading package words to /home/gquispe/nltk_data...
[nltk_data]   Package words is already up-to-date!
[nltk_data] Downloading package omw-1.4 to /home/gquispe/nltk_data...
[nltk_data]   Package omw-1.4 is already up-to-date!
/home/gquispe/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors
Sin reglas de juego claras y justas en lo económico y en lo social, donde lo único permanente es el beneficio creciente de los sectores mas concentrados de ·la economía.
503 -1 1
 0    272578
-1     94401
 1     81118
Name: libertad_economica_score, dtype: int64
 0    346331
-1     58982
 1     42784
Name: libertad_personal_score, dtype: int64
 0    123
-1    118
 1     59
Name: libertad_economica_score, dtype: int64
 0    157
-1     77
 1     66
Name: libertad_personal_score, dtype: int64
Batch 8/90 procesado y guardado.
Batch 9/90 procesado y guardado.
Batch 10/90 procesado y guardado.
Batch 11/90 procesado y guardado.
Batch 12/90 procesado y guardado.
Batch 13/90 procesado y guardado.
Batch 14/90 procesado y guardado.
Batch 15/90 procesado y guardado.
Batch 16/90 procesado y guardado.
Batch 17/90 procesado y guardado.
Batch 18/90 procesado y guardado.
Batch 19/90 procesado y guardado.
Batch 20/90 procesado y guardado.
Batch 21/90 procesado y guardado.
Batch 22/90 procesado y guardado.
Batch 23/90 procesado y guardado.
Batch 24/90 procesado y guardado.
Batch 25/90 procesado y guardado.
Batch 26/90 procesado y guardado.
Batch 27/90 procesado y guardado.
Batch 28/90 procesado y guardado.
Batch 29/90 procesado y guardado.
Batch 30/90 procesado y guardado.
Batch 31/90 procesado y guardado.
Batch 32/90 procesado y guardado.
Batch 33/90 procesado y guardado.
Batch 34/90 procesado y guardado.
Batch 35/90 procesado y guardado.
Batch 36/90 procesado y guardado.
Batch 37/90 procesado y guardado.
Batch 38/90 procesado y guardado.
Batch 39/90 procesado y guardado.
Batch 40/90 procesado y guardado.
Batch 41/90 procesado y guardado.
Batch 42/90 procesado y guardado.
Batch 43/90 procesado y guardado.
Batch 44/90 procesado y guardado.
Batch 45/90 procesado y guardado.
Batch 46/90 procesado y guardado.
Batch 47/90 procesado y guardado.
Batch 48/90 procesado y guardado.
Batch 49/90 procesado y guardado.
Batch 50/90 procesado y guardado.
Batch 51/90 procesado y guardado.
Batch 52/90 procesado y guardado.
Batch 53/90 procesado y guardado.
Batch 54/90 procesado y guardado.
Batch 55/90 procesado y guardado.
Batch 56/90 procesado y guardado.
Batch 57/90 procesado y guardado.
Batch 58/90 procesado y guardado.
Batch 59/90 procesado y guardado.
Traceback (most recent call last):
  File "/home/gquispe/snap/snapd-desktop-integration/178/Documents/Political_Analysis_With_Transformers/data/preprocess/preprocesamiento.py", line 316, in <module>
    procesar_por_batches(df_crude, batch_size, output_prefix)
  File "/home/gquispe/snap/snapd-desktop-integration/178/Documents/Political_Analysis_With_Transformers/data/preprocess/preprocesamiento.py", line 304, in procesar_por_batches
    batch['text_processed'] = batch['Text'].apply(preprocesar_texto)  # Procesar batch
  File "/usr/lib/python3/dist-packages/pandas/core/series.py", line 4357, in apply
    return SeriesApply(self, func, convert_dtype, args, kwargs).apply()
  File "/usr/lib/python3/dist-packages/pandas/core/apply.py", line 1043, in apply
    return self.apply_standard()
  File "/usr/lib/python3/dist-packages/pandas/core/apply.py", line 1098, in apply_standard
    mapped = lib.map_infer(
  File "pandas/_libs/lib.pyx", line 2859, in pandas._libs.lib.map_infer
  File "/home/gquispe/snap/snapd-desktop-integration/178/Documents/Political_Analysis_With_Transformers/data/preprocess/preprocesamiento.py", line 242, in preprocesar_texto
    texto_sin_ambiguedad = remove_sarcasm(texto_limpio)
  File "/home/gquispe/snap/snapd-desktop-integration/178/Documents/Political_Analysis_With_Transformers/data/preprocess/preprocesamiento.py", line 230, in remove_sarcasm
    sentiment = sentiment_classifier(text)[0]
  File "/home/gquispe/.local/lib/python3.10/site-packages/transformers/pipelines/text_classification.py", line 156, in __call__
    result = super().__call__(*inputs, **kwargs)
  File "/home/gquispe/.local/lib/python3.10/site-packages/transformers/pipelines/base.py", line 1257, in __call__
    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)
  File "/home/gquispe/.local/lib/python3.10/site-packages/transformers/pipelines/base.py", line 1264, in run_single
    model_outputs = self.forward(model_inputs, **forward_params)
  File "/home/gquispe/.local/lib/python3.10/site-packages/transformers/pipelines/base.py", line 1164, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
  File "/home/gquispe/.local/lib/python3.10/site-packages/transformers/pipelines/text_classification.py", line 187, in _forward
    return self.model(**model_inputs)
  File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gquispe/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 1695, in forward
    outputs = self.bert(
  File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gquispe/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 1077, in forward
    embedding_output = self.embeddings(
  File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gquispe/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 216, in forward
    embeddings += position_embeddings
RuntimeError: The size of tensor a (625) must match the size of tensor b (512) at non-singleton dimension 1
